# Fusion 360 Copilot Assistant - Directory Structure

```
fusion_copilot_addin/
â”‚
â”œâ”€â”€ ğŸ“„ manifest.json                    Fusion add-in configuration
â”œâ”€â”€ ğŸ“„ main.py                          Add-in entry point
â”œâ”€â”€ ğŸ“„ config.py                        Configuration and settings
â”‚
â”œâ”€â”€ ğŸ“ core/                            Core orchestration
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ orchestrator.py                 Request router and coordinator
â”‚   â”œâ”€â”€ context.py                      Live Fusion context capture
â”‚   â”œâ”€â”€ executor.py                     Safe code execution + diagnostics
â”‚   â””â”€â”€ codegen.py                      Prompt building and response parsing
â”‚
â”œâ”€â”€ ğŸ“ tools/                           Integration utilities
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ filesystem.py                   Project scanning, tool libraries
â”‚   â”œâ”€â”€ geometry_extract.py             Mesh/geometry metadata extraction
â”‚   â””â”€â”€ vision_extract.py               OCR, blueprint analysis
â”‚
â”œâ”€â”€ ğŸ“ ui/                              User interface
â”‚   â”œâ”€â”€ panel.html                      Chat panel markup
â”‚   â”œâ”€â”€ panel.css                       Styling (light/dark theme)
â”‚   â””â”€â”€ panel.js                        Client-side logic
â”‚
â”œâ”€â”€ ğŸ“ scripts/                         Utilities and examples
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ sandbox_runner.py               Isolated execution utilities
â”‚   â””â”€â”€ examples.py                     Example scripts (parametric parts, CAM)
â”‚
â”œâ”€â”€ ğŸ“„ README.md                        Full documentation
â”œâ”€â”€ ğŸ“„ REQUIREMENTS.md                  Dependencies and setup
â”œâ”€â”€ ğŸ“„ ARCHITECTURE.md                  (this file) Structure overview
â”‚
```

## File Descriptions

### Configuration Files
- **manifest.json**: Fusion 360 add-in manifest - tells Fusion how to load the add-in
- **config.py**: Central configuration - LLM backends, UI settings, feature flags
- **REQUIREMENTS.md**: Python and system dependencies

### Entry Point
- **main.py**: Initializes the add-in when Fusion starts, sets up UI and command handlers

### Core Modules

#### orchestrator.py
Coordinates the entire flow:
- Receives chat messages from UI
- Calls context capture
- Sends requests to LLM
- Routes code to executor
- Handles results/errors

#### context.py
Captures live Fusion 360 state for AI prompts:
- Document name, file path, units
- Selected entities (faces, edges, bodies)
- User parameters and their values
- Component structure
- CAM context (if in CAM workspace)
- Returns structured JSON

#### executor.py
Safely runs generated Fusion API code:
- Transaction management (begin/commit)
- Output/error capture
- Stack trace formatting
- Error diagnosis (common patterns)
- Suggests fixes for common mistakes

#### codegen.py
Code generation infrastructure:
- Builds system prompts with context
- Parses LLM responses (JSON, Markdown)
- Extracts title, plan, code, notes
- Generates patch diffs for modifications

### Tools Module

#### filesystem.py
Project directory integration:
- Scans for geometry files (STEP, STL, IGES, OBJ)
- Reads project documentation
- Loads tool libraries (JSON)
- Read-only access by default

#### geometry_extract.py
Geometry metadata extraction:
- Bounding boxes
- Face/edge counts
- Feature detection (holes, pockets)
- Mesh information

#### vision_extract.py
Image and PDF analysis:
- OCR text extraction from blueprints
- Dimension detection
- PDF specification extraction

### UI Module

#### panel.html
Chat interface structure:
- Message history
- User input area
- Code preview panel
- Execution/error displays
- Settings modal

#### panel.css
Professional styling:
- Light and dark themes
- Responsive layout
- Syntax highlighting for code
- Loading animations
- Error/success indicators

#### panel.js
Client-side logic:
- Message sending/display
- Code panel control
- Settings persistence
- Event handling
- Mock LLM responses (replaced with real backend)

### Scripts Module

#### sandbox_runner.py
Isolated code execution utilities:
- Captures stdout/stderr
- Exception handling
- Execution timing
- Safe globals scope

#### examples.py
Reference implementations:
- Parametric bracket generation
- CAM setup creation
- Drawing generation
- Best practices examples

## Data Flow

```
User Input (Chat)
    â†“
[panel.js sends message]
    â†“
orchestrator.process_chat_message()
    â†“
context_capture.get_runtime_context()  â† Reads live Fusion state
    â†“
[Build prompt with context]
    â†“
[Call LLM (OpenAI/Ollama/Offline)]
    â†“
codegen.parse_llm_response()
    â†“
[Show code panel with plan, code, notes]
    â†“
User clicks "Apply"
    â†“
executor.run_code()
    â†“
[Execute in Fusion transaction]
    â†“
[Show result or error]
    â†“
[User can Undo via Fusion]
```

## Extension Points

### Adding a New LLM Backend
1. Create `llm_backends/my_backend.py`
2. Implement `LLMBackend` interface
3. Update `config.py` to register backend
4. UI automatically supports it

### Adding Custom Tools
1. Create `tools/my_tool.py`
2. Implement tool interface
3. Register in `orchestrator.py`
4. Include in context prompts

### Custom Workflows
1. Add workflow class to `core/workflows.py`
2. Register in `orchestrator.py`
3. UI routing handles it

## Naming Conventions

- `_private_method()` - Internal functions
- `PUBLIC_CONSTANT` - Configuration constants
- `snake_case` - Python variables/functions
- `camelCase` - JavaScript variables
- `PascalCase` - Python classes, JS classes

## Error Handling Strategy

1. **User-facing errors**: Clear messages + suggestions
2. **API errors**: Diagnose and offer fixes
3. **Network errors**: Fallback to offline mode
4. **State errors**: Validate Fusion state before execution

## Testing Strategy

- Unit tests for core modules
- Integration tests for orchestrator
- Mock Fusion API for offline testing
- E2E tests with actual Fusion if available

## Performance Considerations

- Context capture: ~100-500ms per request
- LLM inference: 2-30s depending on backend
- Code execution: 100ms - 5s depending on operation
- UI responsiveness: Never block on LLM calls (async)

---

**Current Status**: Phase 1 Infrastructure Complete âœ“
